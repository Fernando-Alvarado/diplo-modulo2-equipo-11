43---
title: "Proyecto final módulo 2"
author: "Equipo - 11"
output: html_document
---
# Integrantes:

+ Gomez Santiago Diego Rol: Administrador
+ Bryant Canseco Hernandez Rol: Colaborador 1
+ Alvarado Palacios Fernando  Rol: Colaborador 2



```{r setup, include=FALSE}
# Empezamos limpiando nuestro ambiente


# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
	echo = FALSE,
	fig.align = "center",
	fig.dim = c(5.0, 4.0),
	fig.pos = "H",
# Agregamos configuraciones para evitar mensajes de advertencias y de errores en el archivo
	message = FALSE,
	warning = FALSE,
	error = F
)

# Librerias a usar en este proyecto 
library(dplyr)
library(readr)
library(ggplot2)
library(countrycode)
library(naniar)
library(esquisse)
library(knitr)   #Libreria para hacer tabalas mas bonitas
library(patchwork) #Orden de las librerias
library(DBI)
library(dbplyr)
library(RSQLite)
library(visdat) #Ver datos faltantes en un df
library(lubridate)



# Rutas que vamos a trabajar, cada quien tendra una ruta diferente

setwd("C:/Users/ferna/Documents/Proyectos_Diplomado/diplo-modulo2-equipo-11/Data")
#setwd("C:/Users/diego/Documents/Ingeniería_Ambiental/Diplomado/Modulo_1/Proyecto_M1_P1/colaboracion-git-equipo-11/Data")
#setwd("/Users/bryantcanseco/Desktop/UNAM/Diplomados/Ciencia de Datos- UNAM/diplo-modulo2-equipo-11/Data")

```



```{r Data}
setwd("C:/Users/ferna/Documents/Proyectos_Diplomado/diplo-modulo2-equipo-11/Data")
#setwd("/Users/bryantcanseco/Desktop/UNAM/Diplomados/Ciencia de Datos- UNAM/diplo-modulo2-equipo-11/Data")
conn <- DBI::dbConnect(RSQLite::SQLite(), "vuelos.db")

```


```{r ExploracionBaseDatos}

dbListTables(conn)

# Leyendo nuestras tablas como datafrmaes, para poder trabajar mejor con ellos
aerolineas <- dbReadTable(conn, "aerolineas")
aeropuertos <- dbReadTable(conn, "aeropuertos")
aviones <- dbReadTable(conn, "aviones")
clima <- dbReadTable(conn, "clima")
vuelos <- dbReadTable(conn, "vuelos")


```



Haciendo una analisis preliminar de los datos, podemos ver que tenemos 5 tablas en nuestra base de datos, aerolineas, aeropuertos, aviones, clima y vuelos.
En donde:


La tabla `airlines` contiene información sobre las aerolíneas,  donde:

- **carrier**: Abreviación o código de la aerolínea.
- **name**: Nombre completo de la aerolínea.

La tabla `aeropuertos` contiene información de diferentes aeropuertos, donde:

- **faa**: Código identificador del aeropuerto.
- **name**: Nombre del aeropuerto.
- **lat**: Latitud del aeropuerto.
- **lon**: Longitud del aeropuerto.
- **alt**: Altitud sobre el nivel del mar (en pies).
- **tz**: Zona horaria numérica respecto a UTC.
- **dst**: Estado del horario de verano (A = activo).
- **tzone**: Zona horaria en formato texto (por ejemplo, "America/New_York").


La tabla `planes` describe las características de los aviones, donde:

- **tailnum**: Matrícula del avión.
- **year**: Año de fabricación.
- **type**: Tipo de aeronave.
- **manufacturer**: Fabricante del avión.
- **model**: Modelo del avión.
- **engines**: Número de motores.
- **seats**: Número de asientos disponibles.
- **speed**: Velocidad (puede contener valores NA).
- **engine**: Tipo de motor (por ejemplo, Turbo-fan).

La tabla `clima` contiene datos meteorológicos por hora en los aeropuertos, donde:

- **origin**: Código del aeropuerto.
- **year, month, day, hour**: Fecha y hora de la medición.
- **temp**: Temperatura (°F).
- **dewp**: Punto de rocío (°F).
- **humid**: Humedad relativa (%).
- **wind_dir**: Dirección del viento (en grados).
- **wind_speed**: Velocidad del viento (mph).
- **wind_gust**: Ráfaga máxima de viento (mph).
- **precip**: Precipitación (pulgadas).
- **pressure**: Presión atmosférica (milibares).
- **visib**: Visibilidad (millas).
- **time_hour**: Fecha y hora unificadas como objeto POSIXct.


La tabla `vuelos` contiene datos sobre más de 300,000 vuelos desde NYC en el año 2013. Las variables principales incluyen:

- **year, month, day**: Año, mes y día del vuelo.
- **dep_time**: Hora real de salida (formato HHMM).
- **sched_dep_time**: Hora programada de salida.
- **dep_delay**: Retraso en la salida (en minutos).
- **arr_time**: Hora real de llegada.
- **sched_arr_time**: Hora programada de llegada.
- **arr_delay**: Retraso en la llegada (en minutos).
- **carrier**: Código de la aerolínea (relacionado con `airlines`).
- **flight**: Número del vuelo.
- **tailnum**: Matrícula del avión (relacionado con `planes`).
- **origin**: Aeropuerto de origen.
- **dest**: Aeropuerto de destino.
- **air_time**: Tiempo de vuelo (en minutos).
- **distance**: Distancia recorrida (en millas).
- **hour, minute**: Hora y minuto extraídos de la hora programada.
- **time_hour**: Marca temporal POSIXct que representa la hora del vuelo.



## Usando visadat para ver los datos perdidos


```{r}
# AEROLINEAS: estructura y valores faltantes
vis_dat(aerolineas)
vis_miss(aerolineas)
```

```{r}
# AEROPUERTOS: estructura y valores faltantes
vis_dat(aeropuertos)
vis_miss(aeropuertos)
```

```{r}
# AVIONES: estructura y valores faltantes
vis_dat(aviones)
vis_miss(aviones)
```

```{r}
# CLIMA: estructura y valores faltantes
vis_dat(clima)
vis_miss(clima)
```






Para trabajar con los datos de vuelos haremos un muestro ya que tenemos demasiados datos, tenemos `r length(vuelos$day) ` y la funcion `vis_dat` no puede con tanto, por lo que tomaremos una muestra de 10,000 filas para trabajar.


```{r}
# VUELOS: estructura y valores faltantes

vuelos_muestra <- slice_sample(vuelos, n = 5000)

vis_dat(vuelos_muestra)
vis_miss(vuelos_muestra)
```




# Vuelos de NYC


```{r, echo=FALSE}
# Utilizaremos las tablas de la base de datos vuelos.db que incluye información de:
# 
# - flights: Detalles de todos los vuelos que salieron de NYC (JFK, LGA, EWR) en 2013.
# - airlines: Códigos y nombres de aerolíneas.
# - airports: Información sobre aeropuertos, incluyendo ubicación.
# - planes: Datos sobre aeronaves, incluyendo año de fabricación.
# - weather: Datos meteorológicos por hora para los aeropuertos de NYC.

head(aeropuertos)
head(aerolineas)
head(aviones)
head(clima)
head(vuelos)


```



```{r, echo=TRUE}
# ¿Qué aerolínea tuvo el mayor retraso promedio en la salida en 2013?

vuelos |> 
  filter(year == 2013) |>
  group_by(carrier) |> 
  summarise(retraso_promedio = mean(dep_delay, na.rm = TRUE)) |>
  arrange(desc(retraso_promedio)) 


aerolineas |> 
  filter(carrier == "F9") |> 
  select(name)

```

**¿Qué aerolínea tuvo el mayor retraso promedio en la salida en 2013?** 

La aerolínea Frontier Airlines (F9) tuvo el mayor retraso promedio en la salida en 2013, con un retraso promedio de 20.21 minutos.

```{r, echo=TRUE}
# ¿Qué día de la semana tuvo más vuelos retrasados en promedio?

vuelos <- vuelos %>% #Modificando los datos de vuelo 
  mutate(fecha = make_date(year, month, day),
         dia_semana = wday(fecha, label = TRUE, abbr = TRUE))

vuelos %>%
  group_by(dia_semana) %>% #Agrupando por dia de la semana y sacando promedio 
  summarise(retraso_promedio = mean(dep_delay, na.rm = TRUE)) %>%
  arrange(desc(retraso_promedio))


```

**¿Qué día de la semana tuvo más vuelos retrasados en promedio?**

La aerolinea con mas retrasos en promedio fue el Jueves, con un retraso promedio de 16.149 

```{r, echo=TRUE}
# ¿Cuál es la distribución de los retrasos en la salida para cada aeropuerto?

vuelos |> group_by(origin) %>% # Agrupando por aeropuerto de origen
  summarise(retraso_promedio = mean(dep_delay, na.rm = TRUE)) %>%
  arrange(desc(retraso_promedio))


```
 ¿Cuál es la distribución de los retrasos en la salida para cada aeropuerto?
 
 El aeropuerto con mayor retraso es el EWR, con un retraso en promedio de 15.10 minutos
 
```{r, echo=TRUE}
# ¿Qué proporción de vuelos se retrasaron más de 30 minutos?

vuelos |> 
  filter(dep_delay > 30) |> 
  summarise(proporcion_retraso = n() / nrow(vuelos)) |> 
  mutate(proporcion_retraso = round(proporcion_retraso * 100, 2))
```
**¿Qué proporción de vuelos se retrasaron más de 30 minutos?**

La proporcion o la probabilidad de que un vuelo se retrase mas de 30 minutos es de 14.34%

```{r, echo=TRUE}
# ¿Qué destinos tuvieron los mayores retrasos promedio en la llegada?

vuelos |> group_by(dest) %>% # Agrupando por aeropuerto de origen
  summarise(retraso_promedio = mean(arr_delay, na.rm = TRUE)) %>% #Retraso en llegada
  arrange(desc(retraso_promedio))


aeropuertos |> 
  filter(faa == "CAE") |> 
  select(name)
```
**¿Qué destinos tuvieron los mayores retrasos promedio en la llegada?**

El aeropuerto con mayor retraso en la llegada es el CAE (Columbia Metropolitan), con un retraso promedio de 41.76 minutos.






```{r, echo=TRUE}
# ¿Qué aerolíneas tuvieron el mayor número de vuelos desde NYC?
vuelos |> 
  filter(origin == c("JFK", "LGA", "EWR")) |>
  group_by(carrier) |>
  summarise(num_vuelos = n()) |>
  arrange(desc(num_vuelos)) 


aerolineas |> 
  filter(carrier == "UA") |> 
  select(name)

```

**¿Qué aerolíneas tuvieron el mayor número de vuelos desde NYC?**

La aerolínea United Airlines (UA) tuvo el mayor número de vuelos desde NYC, con un total de 19,487 vuelos.




```{r, echo=TRUE}
# ¿Cómo varía el retraso de los vuelos según el fabricante de la aeronave?

vuelos |>
  left_join(aviones, by = "tailnum") |>
  group_by(manufacturer) |>
  summarise(retraso_promedio = mean(dep_delay, na.rm = TRUE)) |>
  arrange(desc(retraso_promedio)) 


```


**¿Cómo varía el retraso de los vuelos según el fabricante de la aeronave?**
El fabricante de aeronaves con mayor retraso promedio en la salida es AGUSTA SPA , con un retraso promedio de 32.45 minutos.

```{r, echo=TRUE}
# ¿Los aviones más antiguos tienen más retrasos?

vuelos |>
  left_join(aviones, by = "tailnum") |>
  group_by(year.y) |>
   summarise(retraso_promedio = mean(dep_delay, na.rm = TRUE)) |>
  arrange(desc(retraso_promedio)) 


aviones |> arrange(year) |> 
  select(year) |> 
  head(10)


  
```

**¿Los aviones más antiguos tienen más retrasos?**

No, aunque los avinoes con mas retraso son del año 1972 y 1978, tambien los aviones con menos retrason son del año 1965 y 1977, por lo que al parecer la antiguiedad del avion, no se ve reflejado en el retraso de los aviones 

```{r, echo=TRUE}
# ¿Qué modelos de aviones se utilizan con mayor frecuencia en vuelos desde NYC?

vuelos |>
  left_join(aviones, by = "tailnum") |>
   filter(origin == c("JFK", "LGA", "EWR"), !is.na(model)) |>
   group_by(model) |>
   summarise(num_vuelos = n()) |>
   arrange(desc(num_vuelos))
  

```

**¿Qué modelos de aviones se utilizan con mayor frecuencia en vuelos desde NYC?**

Los modelos que mas se usan en los aeropuertos de NYC son:

- A320-232 con un total de 15,194	 vuelos
- EMB-145LR con un total de 9,448 vuelos
- ERJ 190-100 IGW con un total de 7,948 vuelos




**¿Cuál es la distancia promedio de vuelo por aerolínea?**

El promedio de distancia de vuelo por aerolínea es el siguiente:

```{r, echo=TRUE}
# ¿Cuál es la distancia promedio de vuelo por aerolínea?

vuelos |>
  left_join(aerolineas, by = "carrier") |>
  group_by(name) |>
  summarise(distancia_promedio = mean(distance, na.rm = TRUE)) |>
  arrange(desc(distancia_promedio)) |>
  knitr::kable(digits = 2, caption = "Distancia promedio de vuelo por aerolínea")






```

```{r, echo=TRUE}
# ¿Qué aeropuerto de NYC tuvo el mayor número de retrasos en la salida?

vuelos |>
  filter(origin %in% c("JFK", "LGA", "EWR")) |>
  group_by(origin) |>
  summarise(num_retrasos = sum(dep_delay > 0, na.rm = TRUE)) |>
  arrange(desc(num_retrasos)) 

```
**¿Qué aeropuerto de NYC tuvo el mayor número de retrasos en la salida?**

El aeropuerto de NYC con el mayor número de retrasos en la salida es el EWR	, con un total de 52,711 retrasos.



```{r, echo=TRUE}
# ¿Qué aeropuerto tuvo el menor tiempo promedio de taxi-out?

vuelos |>
  group_by(origin) |>
  summarise(tiempo_promedio_taxi_out = mean(dep_delay, na.rm = TRUE)) |>
  arrange(tiempo_promedio_taxi_out)


```
**¿Qué aeropuerto tuvo el menor tiempo promedio de taxi-out?**

El aeropuerto con el menor tiempo promedio de taxi-out es el LGA, con un tiempo promedio de 10.34 minutos.


**¿Qué porcentaje de vuelos que salen de cada aeropuerto de NYC fueron puntuales?**

El porcentaje de vuelos puntuales que salen de cada aeropuerto de NYC es el siguiente:

```{r, echo=TRUE}
# ¿Qué porcentaje de vuelos que salen de cada aeropuerto de NYC fueron puntuales?

vuelos |>
  group_by(origin) |>
  summarise(pocentaje_puntualidad = sum(dep_delay == 0, na.rm = TRUE) / n() * 100) |>
   knitr::kable(digits = 2, caption = "Porcentaje de vuelos que salen a tiempo")

```

Podemos observar que el porcentajes de vuelo en todos los aeropuertos es muy bajo, lo que puede indicar una saturacion en los aeropuertos de NYC.

**¿Qué aeropuertos de destino tienen el mayor retraso promedio en la llegada para vuelos desde NYC?**

Lista de los 10 aeropuertos con el mayor retraso promedio de llegada para vuelos desde NYC:

```{r, echo=TRUE}
# ¿Qué aeropuertos de destino tienen el mayor retraso promedio en la llegada para vuelos desde NYC?
vuelos |>
  filter(origin %in% c("JFK", "LGA", "EWR")) |>
  left_join(aeropuertos, by = c("dest" = "faa")) |>
  group_by(name) |>
  summarise(retraso_promedio = mean(arr_delay, na.rm = TRUE)) |>
  arrange(desc(retraso_promedio)) |> head(10) |>
  knitr::kable(digits = 2, caption = "Retrasos promedio de llegada por aeropuerto de destino")


```


```{r}
head(aeropuertos)
head(aerolineas)
head(aviones)
head(clima)
head(vuelos)
```



**¿Cómo varían los retrasos en la salida según la hora del día en cada aeropuerto de NYC?**

Tabla con 10 elementos con los retrasos promedio en la salida según la hora del día en cada aeropuerto de NYC

```{r, echo=TRUE}
# ¿Cómo varían los retrasos en la salida según la hora del día en cada aeropuerto de NYC?

vuelos |>
  filter(origin %in% c("JFK", "LGA", "EWR")) |>
  group_by(hour) |>
  summarise(retraso_promedio = mean(dep_delay, na.rm = TRUE)) |> 
  arrange(desc(retraso_promedio)) |> head(10) |>
   knitr::kable(digits = 2, caption = "Retrasos por hora")
```


```{r, echo=TRUE}
# ¿Cuál es la correlación entre la velocidad del viento y los retrasos en la salida?
```

```{r, echo=TRUE}
# ¿Los vuelos experimentan más retrasos en días con lluvias intensas?
```

```{r, echo=TRUE}
# ¿Cómo afecta la temperatura a los retrasos de los vuelos?
```

```{r, echo=TRUE}
# ¿Cómo afectan los niveles de visibilidad a los retrasos en la llegada?
```

```{r, echo=TRUE}
# ¿La alta humedad se relaciona de alguna manera con los tiempos de taxi-out más largos?
```





# ========================================
# Subsección 2: Análisis de calidad del café
# ========================================

```{r}
# En esta sección analizamos el conjunto de datos coffee_ratings.csv,
# que contiene información detallada sobre muestras de café evaluadas
# en diferentes atributos físicos y sensoriales.

# Cargamos las librerías necesarias
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(readr)
library(ggplot2)
library(visdat)   # Para visualización de datos faltantes
setwd("/Users/bryantcanseco/Desktop/UNAM/Diplomados/Ciencia de Datos- UNAM/diplo-modulo2-equipo-11/Data")

# Leemos el archivo CSV
datos <- readr::read_csv("coffee_ratings.csv")


```
#Actividad 0: Análisis de valores faltantes
```{r}
# Analizamos los tipos de datos y la presencia de valores faltantes
vis_dat(datos)
vis_miss(datos)

```
Como parte del análisis exploratorio inicial, visualizamos los datos faltantes del conjunto coffee_ratings.csv mediante las funciones vis_dat() y vis_miss() de la librería {visdat}. Esta exploración fue esencial para entender la calidad y estructura del conjunto de datos antes de realizar transformaciones más complejas.

Lo que observamos en vis_dat():
Este gráfico nos permitió visualizar el tipo de dato (caracter o numérico) de cada columna y resaltar las ausencias mediante líneas grises.

Identificamos que los datos numéricos están muy completos, especialmente aquellos usados para el análisis sensorial (aftertaste, acidity, body, etc.), lo cual validó su uso en las visualizaciones posteriores.

En cambio, las variables tipo texto (character) presentan más ausencias, destacando farm_name, ico_number, mill y region.

Lo que complementamos con vis_miss():
Esta visualización nos ofreció el porcentaje exacto de valores faltantes por columna, confirmando que el conjunto tiene un 6.9% de celdas incompletas.

Las columnas con mayor proporción de valores faltantes fueron:

farm_name (~60%)
mill (~26%)
ico_number y altitude (~16%)
processing_method (~13%)

A pesar de ello, las variables más importantes para nuestras visualizaciones (como total_cup_points, species, acidity, aftertaste, body) tienen cobertura completa (0% de NA).

#Actividad 1: Crear columna color2 con codificación por color
```{r}
datos <- datos |> 
  mutate(
    color2 = case_when(
      is.na(color) ~ NA_character_,
      color == "Green" ~ "#00FF66",
      color == "Bluish-green" ~ "#CCEBC5",
      color == "Blue-green" ~ "#BFFFFF",
      TRUE ~ NA_character_
    )
  )

```

Codificamos visualmente la variable color con tonos representativos. Esto nos ayudará en las visualizaciones posteriores.


# Actividad 2: Crear bag_weight2 como versión numérica de bag_weight
```{r}

# Extraemos solo los números de la columna 'bag_weight' y los convertimos a numérico
datos <- datos |> 
  mutate(
    bag_weight2 = as.numeric(gsub("[^0-9.]", "", bag_weight))
  )

# Contamos cuántas observaciones tenían texto válido pero NO pudieron convertirse a número
sum(is.na(datos$bag_weight2) & !is.na(datos$bag_weight))



```



#Actividad 3: Separar processing_method en method1 y method2
```{r}
datos <- datos |> 
  mutate(
    method1 = word(processing_method, 1, sep = " / "),
    method2 = word(processing_method, 2, sep = " / ")
  )

# Observaciones que no pudieron dividirse bien
sum(is.na(datos$method1) | is.na(datos$method2))
#Dividimos los métodos de procesamiento en dos partes para un análisis más detallado, y cuantificamos los casos con ambigüedad.

```


#Actividad 4 – Separar expiration en expiration_day, expiration_month, expiration_year
```{r}

datos <- datos |> 
  mutate(
    # Quitamos sufijos como 'st', 'nd', 'rd', 'th'
    expiration_clean = str_replace_all(expiration, "(\\d+)(st|nd|rd|th)", "\\1"),
    
    # Convertimos a formato fecha
    expiration_date = mdy(expiration_clean),
    
    # Extraemos año, mes y día correctamente
    expiration_year = year(expiration_date),
    expiration_month = month(expiration_date),
    expiration_day = day(expiration_date)
  )


```


#Actividad 5 – Separar harvest_year en harvest_mes y harvest_anio
```{r}

library(dplyr)
library(stringr)

datos <- datos |> 
  mutate(
    # Extraemos el primer nombre de mes si existe (palabra entre A-Z)
    harvest_mes = str_extract(harvest_year, regex("[A-Za-z]{3,}", ignore_case = TRUE)),

    # Extraemos el primer año de 4 dígitos que aparezca
    harvest_anio = str_extract(harvest_year, "\\d{4}"),
    
    # Convertimos el año a número (para evitar "character")
    harvest_anio = as.numeric(harvest_anio)
  )
# Casos con texto en harvest_year pero sin año o mes detectado
ambig <- datos |> 
  filter(!is.na(harvest_year) & (is.na(harvest_anio) | is.na(harvest_mes)))

nrow(ambig)  # <- Esto es el número de observaciones ambiguas


```
En esta actividad extraemos el mes (harvest_mes) y el año (harvest_anio) de la cosecha a partir del campo harvest_year, el cual contiene una gran diversidad de formatos.
Usamos expresiones regulares para identificar el primer nombre de mes (como "July" o "March") y el primer número de cuatro dígitos que corresponde al año.
Esta transformación permite realizar análisis más precisos por periodo de cosecha.
Un total de r nrow(ambig) observaciones no pudieron descomponerse correctamente por contener abreviaturas, formatos atípicos o entradas sin estructura, como "4T/2010", "TEST", o "mmm"


# Actividad 6 – Visualización con ggplot2
```{r}

# Visualizamos acidez vs. calidad y usamos color2 para pintar los puntos
datos |> 
  filter(!is.na(color2)) |>  # Excluimos NA porque no tienen color asignado
  ggplot(aes(x = acidity, y = total_cup_points, color = color2)) +
  geom_point(size = 2.5, alpha = 0.7) +
  scale_color_identity() +  # Usa el color literal contenido en color2
  labs(
    title = "Relación entre acidez, calidad de taza y color del grano",
    subtitle = "Los colores representan el tipo de grano: Green, Bluish-green, Blue-green",
    x = "Acidez",
    y = "Total de puntos en taza"
  ) +
  theme_minimal(base_size = 13) +
  theme(plot.title = element_text(face = "bold"))


```
En esta visualización relacionamos la acidez (acidity) con la puntuación total de taza (total_cup_points), diferenciando los puntos según el color del grano (color2).
Observamos que 870 muestras están clasificadas como "Green" (#00FF66), mientras que 469 observaciones no tenían un color definido, por lo que no se visualizan con un código de color.
Como resultado, todos los puntos coloreados aparecen en el mismo tono de verde. Aun así, el gráfico permite observar una clara concentración de muestras con acidez entre 6 y 8, y puntuaciones superiores a 80 puntos.


# Actividad 7 – Visualización de densidad de bag_weight2 por species
```{r}
library(ggplot2)

# Visualización refinada
datos |> 
  filter(bag_weight2 <= 150) |>  # Ajustamos el filtro para ver mejor el rango relevante
  ggplot(aes(x = bag_weight2, fill = species, color = species)) +
  geom_density(alpha = 0.4, size = 1.1) +
  scale_fill_manual(values = c("#D95F02", "#1B9E77")) +
  scale_color_manual(values = c("#D95F02", "#1B9E77")) +
  labs(
    title = "Distribución de pesos de bolsa por especie de café",
    subtitle = "Visualización truncada hasta 150 kg para mayor claridad",
    x = "Peso de bolsa (kg)",
    y = "Densidad",
    fill = "Especie",
    color = "Especie"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold")
  )



```
En esta visualización refinada mostramos la distribución del peso de las bolsas de café (bag_weight2) diferenciadas por especie (species).
Para mejorar la legibilidad, truncamos visualmente el eje X a 150 kg, lo que permitió enfocarnos en el rango comercialmente más relevante.
Se observa una marcada concentración alrededor de los 60 kg, especialmente en la especie Arabica. Esto es consistente con las prácticas comerciales estándar de exportación de café verde.
El gráfico emplea una paleta de colores más contrastante y líneas suaves para facilitar su interpretación visual y presentación profesional.


#Actividad 8 – Gráfico de total_cup_points vs. año/mes de expiración
```{r}

# Lista de países objetivo
paises_objetivo <- c("Mexico", "Brazil", "Colombia", "Guatemala")

# Visualización
datos |> 
  filter(country_of_origin %in% paises_objetivo,
         !is.na(expiration_year),
         !is.na(expiration_month)) |> 
  mutate(exp_date = make_date(expiration_year, expiration_month, 1)) |> 
  ggplot(aes(x = exp_date, y = total_cup_points, color = country_of_origin)) +
  geom_jitter(width = 15, size = 2.3, alpha = 0.7) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    title = "Relación entre fecha de expiración y calidad de taza",
    subtitle = "Cafés de México, Brasil, Colombia y Guatemala",
    x = "Fecha de expiración (año/mes)",
    y = "Puntuación total de taza",
    color = "País de origen"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold")
  )

```
En esta actividad exploramos la relación entre la fecha de expiración del café (expiration_year y expiration_month) y la puntuación total de calidad en taza (total_cup_points) para los cafés provenientes de México, Brasil, Colombia y Guatemala.
Se transformó la fecha de expiración en un objeto de tipo fecha (exp_date), permitiendo analizarla en un eje temporal.
La gráfica muestra que las puntuaciones se concentran mayoritariamente entre 80 y 85 puntos, independientemente del país y del año de expiración.
Aunque no se observan tendencias claras o patrones temporales fuertes, el análisis permite identificar cafés con puntajes altos o bajos en momentos particulares del tiempo.
La visualización también pone en evidencia que México es el país con más registros en este subconjunto.


# Actividad 9 – Relación entre mes de expiración y altitud (para cafés 2016–2017 de 4 países)
```{r}

# Definimos los países que nos interesan analizar
paises_objetivo <- c("Mexico", "Brazil", "Colombia", "Guatemala")

# Filtramos el conjunto de datos original
# Solo conservamos los registros de los países seleccionados,
# con año de expiración 2016 o 2017,
# y que no tengan datos faltantes en las columnas de altitud ni en el mes de expiración.
datos_filtrados <- datos |> 
  filter(
    country_of_origin %in% paises_objetivo,
    expiration_year %in% c(2016, 2017),
    !is.na(expiration_month),
    !is.na(altitude_low_meters),
    !is.na(altitude_high_meters),
    !is.na(altitude_mean_meters)
  )

# Reorganizamos el dataset para facilitar la visualización
# Convertimos las columnas de altitud a formato "long" para usar facet_wrap
datos_long <- datos_filtrados |> 
  pivot_longer(
    cols = c(altitude_low_meters, altitude_high_meters, altitude_mean_meters),
    names_to = "tipo_altitud",
    values_to = "valor_altitud"
  )

# Visualizamos los datos con boxplots por mes de expiración y tipo de altitud
ggplot(datos_long, aes(x = factor(expiration_month), y = valor_altitud, fill = tipo_altitud)) +
  geom_boxplot(alpha = 0.7, outlier.color = "red", outlier.size = 1.5) +
  facet_wrap(~ tipo_altitud, scales = "free_y") +  # Un panel por tipo de altitud
  labs(
    title = "Relación entre mes de expiración y altitud (2016–2017)",
    subtitle = "Cafés de México, Brasil, Colombia y Guatemala",
    x = "Mes de expiración",
    y = "Altitud (metros)",
    fill = "Tipo de altitud"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom"
  )

```
Las tres dimensiones de altitud (low, high, mean) muestran una distribución relativamente constante a lo largo de los meses, lo cual sugiere que la altitud del cultivo no varía drásticamente con el mes de expiración.

Sin embargo, hay algunos outliers interesantes en los meses de mayo, julio y septiembre, especialmente en la altitud más alta (altitude_high_meters). Estos podrían estar asociados a cafés de regiones montañosas específicas o a errores de captura de datos.

Visualmente, el rango intercuartílico parece ser más estrecho en los meses finales del año, lo que podría indicar una menor variabilidad en altitud en cafés que expiran en esos meses.

Las altitudes promedios (altitude_mean_meters) muestran una tendencia central alrededor de 1200–1500 metros, lo cual coincide con altitudes típicas de producción de cafés de alta calidad.


#Actividad 10: Relación entre aftertaste, acidity, body y species
```{r}
# Cargamos la librería para gráficos multivariados
library(GGally)

# Creamos el gráfico multivariado
datos |> 
  select(aftertaste, acidity, body, species) |> 
  filter(!is.na(species)) |> 
  ggpairs(aes(color = species, alpha = 0.5)) +
  theme_minimal()

```
Para esta actividad decidimos utilizar la función ggpairs() de la librería {GGally}, ya que permite observar de forma simultánea:

Las correlaciones numéricas entre variables continuas.

La distribución individual de cada variable.

La relación cruzada de variables por especie de grano, facilitando la diferenciación por color.

Las correlaciones entre aftertaste, acidity y body son altas y positivas en general (mayores a 0.7), especialmente dentro de la especie Arabica.

Se observa claramente que la especie Arabica domina la muestra, tanto en cantidad como en la intensidad de los atributos sensoriales.

Aunque la especie Robusta está subrepresentada en la base de datos, su comportamiento es visiblemente diferente: menor variabilidad y puntuaciones más concentradas.

El patrón de distribuciones normales truncadas sugiere una buena homogeneidad de los datos sensoriales, al menos para la especie Arabica.




# Analizando letras de canciones



